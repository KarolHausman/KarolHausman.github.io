<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Karol Hausman">
    <meta name="author" content="Karol Hausman">

    <title>Karol Hausman's academic website</title>

    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.css" rel="stylesheet">

    <!-- Custom CSS -->
    <!--<link href="css/grayscale.css" rel="stylesheet" title="default">-->
    <link href="css/grayscale_white.css" rel="stylesheet" title="default">

    <!-- Custom Fonts -->
    <link href="font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="//fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" rel="stylesheet" type="text/css">
    <link href="//fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

	<!--<script type="text/javascript" src="/js/styleswitcher.js"></script>-->

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-63177134-1', 'auto');
  ga('send', 'pageview');

</script>

</head>

<body id="page-top" data-spy="scroll" data-target=".navbar-fixed-top">

    <!-- Navigation -->
    <nav class="navbar navbar-custom navbar-fixed-top" role="navigation">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-main-collapse">
                    <i class="fa fa-bars"></i>
                </button>
                <a class="navbar-brand page-scroll" href="#page-top">
                    <i class="fa fa-chevron-circle-up"></i> HOME <!--<span class="light">Home</span>--> 
                </a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse navbar-right navbar-main-collapse">
                <ul class="nav navbar-nav">
                    <!-- Hidden li included to remove active class from about link when scrolled up past about section -->
                    <li class="hidden">
                        <a href="#page-top"></a>
                    </li>
		    <li>
                        <a class="page-scroll" href="#about">About</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#news">News</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#research">Research</a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>

    <!-- Intro Header -->
    <header class="intro">
        <div class="intro-body">
            <div class="container">
                <div class="row">
                    <div class="col-md-8 col-md-offset-2">
						<div class="rein-intro-bg">
		                    <h1 class="brand-heading">Karol Hausman</h1>								
		                    <p class="intro-text">Researcher in robotics <br>and machine learning			
							</p>
							<a href="mailto:hausmankarol@gmail.com" target="_top" class="fa fa-envelope"></a>
							<a href="http://github.com/KarolHausman" target="_blank" class="fa fa-github"></a>
							<a href="http://www.linkedin.com/pub/karol-hausman/57/b84/592/" target="_blank" class="fa fa-linkedin"></a>
							<a href="http://www.youtube.com/user/MrLolu28" target="_blank" class="fa fa-youtube"></a>   		
						</div>
                        <a href="#about" class="btn btn-circle page-scroll" style="margin-top:100px; color:#f9009a">
                            <i class="fa fa-angle-double-down animated"></i>
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </header>

     <!-- About Section -->
    <section id="about" class="content-section text-center">

		<div class="container">
            		<div class="col-lg-8 col-lg-offset-2 text-justify">
						<img src="img/hausman-new-box.jpg" class="img-circle img-me"/>			
                		<h2 class="text-center text-padded">About</h2>
                		<p>
I'm a Research Scientist at <a href="https://ai.google/research/teams/brain/robotics/" target="_blank">Google Brain</a> in Mountain View working on robotics and machine learning. Quite recently, I finished my PhD at the <a href="http://www.usc.edu/" target="_blank">University of Southern California</a> in the <a href="http://robotics.usc.edu/resl/" target="_blank">Robotics Embedded Systems Lab (RESL)</a> under supervision of Prof.<a href="http://www-robotics.usc.edu/~gaurav/" target="_blank"> Gaurav Sukhatme.</a> While at USC, I was also closely collaborating with <a href="http://www-clmc.usc.edu/Main/HomePage" target="_blank">Stefan Schaal's group</a>. I'm mostly involved in interactive perception, reinforcement learning and probabilistic state estimation, however, I have very broad interests in the fields of robotics and machine learning. While being at RESL I did a number of internships at: <a href="http://www.bosch.us/content/language1/html/rtc.htm" target="blank">Bosch LLC</a> (2013 and 2014) working on <a href="icra15articulation.pdf" target="_blank">active articulation model estimation</a>, <a href="http://www.jpl.nasa.gov" target="blank">NASA JPL</a> (2015) working on <a href="hausman16icra.pdf" target="blank">multi-sensor fusion</a> and <a href="https://www.qualcomm.com/invention/research" target=blank>Qualcomm Research</a> (2016) working on <a href="https://www.youtube.com/watch?v=DPCI5Hxn8R4&feature=youtu.be&t=36m58s" target="blank">active mapping and planning under uncertainty</a>. In summer 2017, I joined <a href="https://deepmind.com" target="blank">Google DeepMind</a> for another exciting internship. <br><br>

My research interests lie in active state estimation, control generation and machine learning for robotics. I investigate interactive perception, by which robots use their manipulation capabilities to gain the most useful perceptual information to model the world and inform intelligent decision making. The paradigm of generating motion to improve state estimation (interactive perception) and task execution (reinforcement learning) is applied throughout my work, in which I show that coupling perception and control together can be beneficial for both fields. More recently, I have been investigating deep reinforcement learning and its applications in robotics. I have evaluated my work on many different platforms including quadrotors, humanoid robots and robotic arms.<br><br>

I studied Mechatronics and Computer Science at <a href="http://www.pw.edu.pl/engpw" target="_blank">Warsaw University of Technology (WUT)</a>, Philosophy at the <a href="http://www.uw.edu.pl/en/" target="_blank">University of Warsaw</a> and <a href="http://www.in.tum.de/en/for-prospective-students/masters-programs/robotics-cognition-intelligence.html" target="_blank">Robotics, Cognition and Intelligence</a> at <a href="http://www.tum.de/en/homepage/" target="_blank">Technical University of Munich (TUM)</a>. In August 2012, I graduated summa cum laude obtaining Master of Robotics degree at WUT. In December 2013, I graduated summa cum laude with a second Master of Computer Science degree from TUM. 

<!--A complete CV can be found <a href="Karol_Hausman_CV.pdf" target="_blank">here</a>. -->
</p>
            		</div>
		</div>

<ul class="list-inline banner-social-buttons text-center">
<li>
		<a href="cv.pdf#zoom=100" target="_blank" class="btn btn-default btn-lg"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">Curriculum Vitae</span></a><!--<a href="cv.pdf#zoom=100" target="_blank" class="btn btn-default btn-lg"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">Curriculum Vitae</span></a>-->
</li>
</ul>

    </section>

<!-- News Section -->
    <section id="news" class="container content-section text-center">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
                <h2>News</h2>
                <ul class="left-text">

          <li>
                        <p> I'm happy to announce that I joined <a href="https://ai.google/research/teams/brain/robotics/" target="_blank">Google Brain</a> in Mountain View as a Research Scientist.</p>
                    </li>

          <li>
                        <p>I successfully defended my PhD Thesis. Thank you to all my committee members: <a href="http://robotics.usc.edu/~gaurav/" target="_blank">Gaurav Sukhatme</a>, <a href="http://www-clmc.usc.edu/~sschaal/" target="_blank">Stefan Schaal</a>, <a href="http://www-bcf.usc.edu/~limjj/" target="_blank">Joseph Lim</a>, <a href="https://people.eecs.berkeley.edu/~pabbeel/" target="_blank">Pieter Abbeel</a> and <a href="http://ruk.usc.edu/bio/gupta/" target="_blank">S.K. Gupta</a>. </p>
                    </li>

          <li>
                        <p>Our <a href="https://openreview.net/forum?id=rk07ZXZRb" target="_blank">paper on robot skill embeddings</a> is accepted for ICLR 2018 in Vancouver! This is the work that I've done while at DeepMind together with their amazing team. </p>
                    </li>
					<li>
                        <p>Our paper titled <a href="pdf/chebotar-hausman-zhang17rss-ws.pdf" target="_blank">“Combining Model-Based and Model-Free Updates for Deep Reinforcement Learning”</a> won the best paper award at the <a href="http://juxi.net/workshop/deep-learning-rss-2017/" target="_blank">RSS 2017 New Frontiers for Deep Learning in Robotics Workshop</a>! </p>
                    </li>
					<li>
						<p> Our work on observability-aware trajectories got picked up by a student at University of Waterloo <a href="http://cglwn.github.io/" target="_blank">James Cagalawan</a>, who prepared a website with nice animations and interactive diagrams that explains our approach. Check it out <a href="http://cglwn.github.io/articles/2017-08-observability-aware-trajectories/" target="_blank">here</a>. 
					</li>
                    <li>
                        <p>I gave invited talks on “Rethinking Perception-Action Loops” at UPenn (05.2017), UW (05.2017), MIT (05.2017) and Google DeepMind (07.2017). Thanks for having me!</p>
                    </li>
					<li>
                        <p>Our work on Deep Reinforcement Learning was featured in the Nvidia CEO Jensen Huang's keynote at the biggest GPU conference - <a href="http://www.gputechconf.com/" target="_blank">GTC 2017</a>! (<a href="http://www.ustream.tv/channel/20165212" target="_blank">video</a> - watch from the 2 hours mark)</p>
                    </li>
                    <li>
                        <p>I'm happy to announce that I will be spending Summer 2017 at <a href="https://deepmind.com/" target="_blank">Google DeepMind</a> in London.</p>
                    </li>
					<li>
                        <p>I'm excited to be in the Program Committee of the <a href="http://rss2017ws.is.tuebingen.mpg.de/" target="_blank">RSS 2017 Workshop: Revisiting Contact - Turning a Problem into a Solution</a>. Please contribute!</p>
                    </li>                    
                    <!--<li>
                        <p>In April 2016, I passed my PhD qualification exam a.k.a. thesis proposal.</p>
                    </li>-->
					<li>
                        <p>I co-organized the <a href="http://rss16iprloc.robotics.usc.edu/" target="_blank"> RSS 2016 Workshop on Robot Environment Interaction for Perception and Manipulation</a>.</p>
                    </li>                    
                    <li>
                        <p>We released our BioTac Grasp Stability Dataset (BiGS)! If you always wanted to do interesting machine learning on complex tactile data, you should try it out! You can find it <a href="http://bigs.robotics.usc.edu/" target="_blank">here</a>.</p>
                    </li>
                    <li>
                        <p>I gave an invited talk on “Multi-Sensor Fusion with Seamless Sensor Switching and Trajectory Optimization for Self-Calibration” at Google Tango (10.2016), UCLA (10.2016) and Qualcomm (06.2016). Thanks for having me!</p>
                    </li>
                    <!--<li>
                        <p>I gave an invited talk on “Active and Interactive Perception” at Stanford (10.2016) and NASA JPL (09.2015). Thank you for the invitations!</p>
                    </li>-->

                </ul>
            </div>
        </div>
    </section>



    <section id="research" class="content-section text-center">
<div class="container">
            <div class="col-lg-8 col-lg-offset-2 text-left">
                <h2 class="text-center">Research</h2>
		<br>

		<ul class="list-inline banner-social-buttons text-center">
		<li>
				<a href="https://scholar.google.com/citations?user=yy0UFOwAAAAJ&hl=en&oi=ao" class="btn btn-default btn-lg"><i class="fa fa-google fa-fw"></i> <span class="network-name">Google Scholar</span></a>
		</li>
		<!--<li>
		<a href="https://www.researchgate.net/profile/Rein_Houthooft" class="btn btn-default btn-lg"><i class="fa fa-flask fa-fw"></i> <span class="network-name">ResearchGate</span></a>
		</li>-->
		</ul>
		<br><br>

		<h3>
		(Deep) Reinforcement and Imitation Learning</br>for robotics
		</h3>

		<p class="text-justify">
		In my research on Deep Reinforcement and Imitation Learning, I focus on how we can apply modern deep learning techniques to classical RL and IL frameworks. <!--while leveraging prior knowledge about the model of the environment. 
By incorporating this prior, we can significantly improve sample efficiency, which enables us to conduct experiments on real robots. -->
		</p>


<table class="entry">
	<tr>
	<th>
	<img width="170" height="120" src="img/thumbnails/embeddings.png" class="rein-paper"/>
	</th>
	<th class="entry">
		<a href="https://openreview.net/forum?id=rk07ZXZRb">Learning an Embedding Space for Transferable Robot Skills</a><br>International Conference on Learning Representations (ICLR), 2018<br>
		<small class="authors">
		K. Hausman, J.T. Springenberg, Z. Wang, N. Heess, M. Riedmiller
		</small>
		<br>
<ul class="list-inline list-inline-x text-left">
<li>
<a href="bibtex/hausman18iclr.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
</li>
<li>
<a href="https://openreview.net/pdf?id=rk07ZXZRb" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>
</li>
<!--<li>
<a href="https://youtu.be/9EDokIauaiM" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-video-camera fa-fw"></i> <span class="network-name">video</span></a>
</li> -->
</ul> 
<!--
<small>
<a href="bibtex/exploration-16.txt">bibtex</a> — <a href="https://arxiv.org/pdf/1611.04717v2.pdf">pdf</a></small>-->

	</th>
	</tr>
	</table>



<table class="entry">
	<tr>
	<th>
	<img width="170" height="100" src="img/thumbnails/intentiongan.png" class="rein-paper"/>
	</th>
	<th class="entry">
		<a href="https://arxiv.org/abs/1705.10479">Multi-Modal Imitation Learning from Unstructured Demonstrations using GANs</a><br>Neural Information Processing Systems (NIPS), 2017<br>
		<small class="authors">
		K. Hausman*, Y. Chebotar*, S. Schaal, G. Sukhatme, J. Lim
		</small>
		<br>
<ul class="list-inline list-inline-x text-left">
<li>
<a href="bibtex/hausman17nips.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
</li>
<li>
<a href="https://arxiv.org/pdf/1705.10479" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>
</li>
<li>
<a href="https://youtu.be/9EDokIauaiM" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-video-camera fa-fw"></i> <span class="network-name">video</span></a>
</li>
</ul>
<!--
<small>
<a href="bibtex/exploration-16.txt">bibtex</a> — <a href="https://arxiv.org/pdf/1611.04717v2.pdf">pdf</a></small>-->

	</th>
	</tr>
	</table>


	<table class="entry">
	<tr>
	<th>
	<img width="170" height="170" src="img/thumbnails/hockey.jpg" class="rein-paper"/>
	</th>
	<th class="entry">
		<a href="https://arxiv.org/abs/1703.03078">Combining Model-Based and Model-Free Updates for Trajectory-Centric Reinforcement Learning</a><br>International Conference on Machine Learning (ICML), 2017<br>
		<small class="authors">
		Y. Chebotar*, K. Hausman*, M. Zhang*, G. Sukhatme, S. Schaal, S. Levine
		</small>
		<br>
<ul class="list-inline list-inline-x text-left">
<li>
<a href="bibtex/chebotar-hausman-zhang17icml.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
</li>
<li>
<a href="https://arxiv.org/pdf/1703.03078.pdf" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>
</li>
<li>
<a href="https://github.com/cbfinn/gps" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-github fa-fw"></i> <span class="network-name">github</span></a>
</li>
<li>
<a href="https://sites.google.com/site/icml17pilqr/" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-video-camera fa-fw"></i> <span class="network-name">video</span></a>
</li>
</ul>
<!--
<small>
<a href="bibtex/exploration-16.txt">bibtex</a> — <a href="https://arxiv.org/pdf/1611.04717v2.pdf">pdf</a></small>-->

	</th>
	</tr>
	</table>

	<table class="entry">
	<tr>
	<th>
	<img width="170" height="150" src="img/thumbnails/regrasping.jpg" class="rein-paper"/>
	</th>
	<th class="entry">
		<a href="pdf/hausman-chebotar16iser.pdf">Generalizing Regrasping with Supervised Policy Learning</a><br>International Symposium on Experimental Robotics (ISER), 2016&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
		<small class="authors">
		Y. Chebotar*, K. Hausman*, O. Kroemer, G. Sukhatme, S. Schaal
		</small>
		<br>
<ul class="list-inline list-inline-x text-left">
<li>
<a href="bibtex/hausman-chebotar16iser.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
</li>
<li>
<a href="pdf/hausman-chebotar16iser.pdf" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>
</li>
<li>
<a href="https://www.youtube.com/watch?v=ZeMmmQ5cxTo" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-video-camera fa-fw"></i> <span class="network-name">video</span></a>
</li>
</ul>
<!--<small>
<a href="bibtex/vime-nips-16.txt">bibtex</a> — <a href="https://arxiv.org/pdf/1605.09674v3.pdf">pdf</a> — <a href="https://github.com/openai/vime">github</a> — <a href="https://openai.com/blog/generative-models/"> blog post </a> — <a href="https://youtu.be/nbbMSMv3v5k">spotlight video</a>
</small>-->
	</th>
	</tr>
	</table>

	<table class="entry">
	<tr>
	<th>
	<img width="170" src="img/thumbnails/regrasping-simple.jpg" class="rein-paper"/>
	</th>
	<th class="entry">
		<a href="pdf/chebotar16iros.pdf">Self-Supervised Regrasping using Spatio-Temporal Tactile Features and Reinforcement Learning</a><br>International Conference on Intelligent Robots and Systems (IROS), 2016<br>
		<small class="authors">
		Y. Chebotar, K. Hausman, Z. Su, G. Sukhatme, S. Schaal
		</small>
		<br>
<ul class="list-inline list-inline-x text-left">
<li>
<a href="bibtex/chebotar16iros.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
</li>
<li>
<a href="pdf/chebotar16iros.pdf" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>
</li>
<li>
<a href="https://www.youtube.com/watch?v=tkPiTMiGLCA&t=50s" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-video-camera fa-fw"></i> <span class="network-name">video</span></a>
</li>
</ul>
<!--
<small>
<a href="bibtex/infogan-nips-16.txt">bibtex</a> — <a href="https://arxiv.org/pdf/1606.03657v1.pdf">pdf</a> — <a href="https://github.com/openai/InfoGAN">github</a> — <a href="https://openai.com/blog/generative-models/"> blog post </a>
</small>
-->
	</th>
	</tr>
	</table>

	<table class="entry">
	<tr>
	<th>
	</th>
	<th class="entry workshops">
		<h4>Workshop Publications</h4>
<a href="pdf/hausman17nips-ws2.pdf">Learning
Skill Embeddings for Transferable Robot Skills</a><br>NIPS Deep Reinforcement Learning Symposium, 2017<br>
		<small class="authors">
		K. Hausman, J.T. Springenberg, Z. Wang, N. Heess, M. Riedmiller
		</small>
		<!--<a href="bibtex/hausman17corl.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a> -->
		<a href="pdf/hausman17nips-ws2.pdf" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>
		<br><br>

		<a href="pdf/hausman17nips-ws1.pdf">Learning Robot Skill Embeddings</a><br>NIPS Workshop on Acting and Interacting in the Real World: Challenges in Robot Learning, 2017<br>
		<small class="authors">
		K. Hausman, J.T. Springenberg, Z. Wang, N. Heess, M. Riedmiller
		</small>
		<!--<a href="bibtex/hausman17corl.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>-->
		<a href="pdf/hausman17nips-ws1.pdf" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>
		<br><br>

		<a href="https://arxiv.org/pdf/1705.10479">IntentionGAN: Multi-Task Imitation Learning from Unstructured Demonstrations</a><br>Conference on Robot Learning (CoRL), 2017<br>
		<small class="authors">
		K. Hausman*, Y. Chebotar*, S. Schaal, G. Sukhatme, J. Lim
		</small>
		<a href="bibtex/hausman17corl.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
		<a href="https://arxiv.org/pdf/1705.10479" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>
		<br><br>
		<a href="pdf/hausman17rss-ws.pdf">IntentionGAN: Multi-Modal Imitation Learning from Unstructured Demonstrations</a><br>RSS Workshop on Learning from Demonstration in High-Dimensional Feature Spaces, 2017<br>
		<small class="authors">
		K. Hausman*, Y. Chebotar*, S. Schaal, G. Sukhatme, J. Lim
		</small>
		<a href="bibtex/hausman17rss-ws.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
		<a href="pdf/hausman17rss-ws.pdf" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>
		<br><br>
		<a href="pdf/chebotar-hausman-zhang17rss-ws.pdf">Combining Model-Based and Model-Free Updates for Deep Reinforcement Learning</a><br>RSS Workshop on New Frontiers for Deep Learning in Robotics, 2017<br><i>Best Paper Award</i><br>
		<small class="authors">
		Y. Chebotar*, K. Hausman*, M. Zhang*, G. Sukhatme, S. Schaal, S. Levine
		</small>
		<a href="bibtex/chebotar-hausman-zhang17rss-ws.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
		<a href="pdf/chebotar-hausman-zhang17rss-ws.pdf" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>
		<br><br>
		<a href="pdf/hausman-chebotar17aaai-ws.pdf">Regrasping using Tactile Perception and Supervised Policy Learning</a><br>AAAI Symposium on Interactive Multi-Sensory Object Perception for Embodied Agents, 2017<br>
		<small class="authors">
		Y. Chebotar, K. Hausman, Z. Su, G. Sukhatme, S. Schaal
		</small>
		<a href="bibtex/hausman-chebotar17aaai-ws.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
		<a href="pdf/hausman-chebotar17aaai-ws.pdf" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>
		<br><br>
		<a href="pdf/hausman-chebotar16iros-ws.pdf">Supervised Policy Fusion with Application to Regrasping</a><br>IROS Workshop on Closed-loop Grasping and Manipulation: Challenges and Progress, 2016<br>
		<small class="authors">
		Y. Chebotar*, K. Hausman*, O. Kroemer, G. Sukhatme, S. Schaal
		</small>
		<a href="bibtex/hausman-chebotar16iros-ws.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
		<a href="pdf/hausman-chebotar16iros-ws.pdf" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>
		<br>
<!--
<small>
<a href="bibtex/icml-16.txt">bibtex</a> — <a href="https://arxiv.org/pdf/1604.06778.pdf">pdf</a> — <a href="https://github.com/rllab/rllab">github</a>
</small>
-->
	</th>
	</tr>
	</table>

		<br><br><br><br>
		<h3>
		Interactive Perception
		</h3>
		<p class="text-justify">
		Recent approaches in Robotics are subsumed by the term Interactive Perception (IP). Within these approaches any kind of forceful interactions with the environment are used to simplify and enhance perception, thereby enabling robust perceptually-guided manipulation behaviors. IP has two benefits. First, physical interaction creates a novel sensory signal that would otherwise not be present. Second, by exploiting knowledge of the regularity in the combined space of sensory data and action parameters, the prediction and interpretation of this novel signal becomes simpler and more robust. For more details, see <a href="https://arxiv.org/abs/1604.03670">our survey paper</a>.
<br>
<!--<img width="100%" src="img/thumbnails/deep_ssvm.png""/>
<br>-->
		</p>

	<table class="entry">
	<tr>
	<th>
		<img width="170" style="margin-bottom: 20px" src="img/thumbnails/ip-survey.png" class="rein-paper"/>
	</th>
		<th class="entry">

		<a href="https://arxiv.org/abs/1604.03670">Interactive Perception: Leveraging Action in Perception and Perception in Action</a>
		<br>IEEE Transactions on Robotics (T-RO), 2016<br>
		<small class="authors">
		J. Bohg*, K. Hausman*, B. Sankaran*, O. Brock, D. Kragic, S. Schaal, G. Sukhatme
		</small>
		<br>
		<ul class="list-inline list-inline-x text-left">
		<li>
		<a href="http://dblp.uni-trier.de/rec/bibtex/journals/corr/BohgHSBKSS16" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
		</li>
		<li>
		<a href="https://arxiv.org/pdf/1604.03670.pdf" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>
		</li>
    <li>
    <a href="https://youtu.be/3JrPkZV0rxY" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-video-camera fa-fw"></i> <span class="network-name">video</span></a>
    </li>
<!--
<small>
<a href="bibtex/pr.txt">bibtex</a> — <a href="http://arxiv.org/pdf/1508.00451v4.pdf">pdf</a>
</small>
-->
	</th>
	</tr>
	</table>

	<table class="entry">

	<tr>
	<th>
<img width="170" src="img/thumbnails/articulation.png" class="rein-paper"/>
	</th>
		<th class="entry">
		
		<a href="pdf/icra15articulation.pdf">Active Articulation Model Estimation through Interactive Perception </a> &emsp; &emsp;<br>International Conference on Robotics and Automation (ICRA), 2015<br>
		<small class="authors">
		K. Hausman, S. Niekum, S. Osentoski , G. Sukhatme 
		</small>
		<br>
<ul class="list-inline list-inline-x text-left">
<li>
<a href="bibtex/hausman15icra.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
</li>
<li>
<a href="pdf/icra15articulation.pdf" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>
</li>
<li>
<a href="https://youtu.be/aFcyq9vG4lI" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-video-camera fa-fw"></i> <span class="network-name">video</span></a>
</li>
</ul>
<!--
<small>
<a href="bibtex/pr.txt">bibtex</a> — <a href="http://arxiv.org/pdf/1508.00451v4.pdf">pdf</a>
</small>
-->
	</th>
	</tr>
	</table>

	<table class="entry">

	<tr>
	<th>
<img width="170" src="img/thumbnails/grasping.png" class="rein-paper"/>
	</th>
		<th class="entry">
		
		<a href="pdf/su15hum.pdf">Force Estimation and Slip Detection for Grip Control using a Biomimetic Tactile Sensor</a><br>International Conference on Humanoid Robotics (Humanoids), 2015<br>
		<small class="authors">
		Z. Su, K. Hausman, Y. Chebotar, A. Molchanov, G. Loeb, G. Sukhatme, S. Schaal 
		</small>
		<br>
<ul class="list-inline list-inline-x text-left">
<li>
<a href="bibtex/su15hum.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
</li>
<li>
<a href="pdf/su15hum.pdf" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>
</li>
</ul>
<!--
<small>
<a href="bibtex/pr.txt">bibtex</a> — <a href="http://arxiv.org/pdf/1508.00451v4.pdf">pdf</a>
</small>
-->
		</th>
		</tr>
	</table>

	<table class="entry">
	<tr>
	<th>
		<img width="170" style="margin-bottom: 20px" src="img/thumbnails/textured.png" class="rein-paper"/>
	</th>
		<th class="entry">

		<a href="https://link.springer.com/book/10.1007/978-3-319-26327-4">Interactive Segmentation of Textured and Textureless Objects</a>
		<br>Chapter in Handling Uncertainty and Networked Structure in Robot Control, L. Busoniu and L. Tamas (eds.), Springer, 2015<br>
		<small class="authors">
		K. Hausman, D. Pangercic, Z. Marton, F. Belent-Benczedi, C. Bersch, M. Gupta, G. Sukhatme, M. Beetz
		</small>
		<br>
<ul class="list-inline list-inline-x text-left">
<li>
<a href="bibtex/springer-ch10.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
</li>
<li>
<a href="https://link.springer.com/book/10.1007/978-3-319-26327-4"" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>
</li>
<li>
<a href="https://www.youtube.com/watch?v=4VVov6E3iiM" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-video-camera fa-fw"></i> <span class="network-name">video</span></a>
</li>
<!--
<small>
<a href="bibtex/pr.txt">bibtex</a> — <a href="http://arxiv.org/pdf/1508.00451v4.pdf">pdf</a>
</small>
-->
		</th>
		</tr>
	</table>

	<table class="entry">
	<tr>
	<th>
		<img width="170" height="200" style="margin-bottom: 20px" src="img/thumbnails/textureless.png" class="rein-paper"/>
	</th>
		<th class="entry">

		<a href="pdf/hausman13interactive.pdf">Tracking-based Interactive Segmentation of Textureless Objects</a>
		<br>International Conference on Robotics and Automation (ICRA), 2013
		<br><i>Best Service Robotics Paper Finalist</i><br>
		<small class="authors">
		K. Hausman, F. Balint-Benczedi, D. Pangercic, Z. Marton,<br>R. Ueda, K. Okada, M. Beetz
		</small>
		<br>
<ul class="list-inline list-inline-x text-left">
<li>
<a href="bibtex/hausman13icra.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
</li>
<li>
<a href="pdf/hausman13interactive.pdf"" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>
</li>
<li>
<a href="https://www.youtube.com/watch?v=Bu4LayrGC1s" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-video-camera fa-fw"></i> <span class="network-name">video</span></a>
</li>
<!--
<small>
<a href="bibtex/infogan-nips-16.txt">bibtex</a> — <a href="https://arxiv.org/pdf/1606.03657v1.pdf">pdf</a> — <a href="https://github.com/openai/InfoGAN">github</a> — <a href="https://openai.com/blog/generative-models/"> blog post </a>
</small>
-->
	</th>
	</tr>
	</table>

	<table class="entry">
	<tr>
	<th>
	</th>
	<th class="entry workshops">
		<h4>Workshop Publications</h4>
		<a href="http://bigs.robotics.usc.edu/">BiGS: BioTac Grasp Stability Dataset</a><br>ICRA Workshop on Grasping and Manipulation Datasets, 2016<br>
		<small class="authors">
		Y. Chebotar, K. Hausman, Z. Su, A. Molchanov, O. Kroemer, G. Sukhatme, S. Schaal<br>
		</small>
		<a href="http://bigs.robotics.usc.edu/" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">website</span></a>
		<a href="bibtex/chebotar16-ws-icra.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
		<a href="pdf/chebotar16-ws-icra.pdf" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>

		<br><br>
		<a href="pdf/zhesu15-ws-bmva.pdf">Slip Classification Using Tangential and Torsional Skin Distortions<br>on a Biomimetic Tactile Sensor</a><br>BMVA Workshop on Visual, Tactile and Force Sensing for Robot Manipulation, 2015<br>
		<small class="authors">
		Z. Su, K. Hausman, Y. Chebotar, A. Molchanov, G. Loeb, G. Sukhatme, S. Schaal
		</small>
		<a href="bibtex/zhesu15-ws-bmva.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
		<a href="pdf/zhesu15-ws-bmva.pdf" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>

		<br><br>
		<a href="pdf/zhesu15-ws-iros.pdf">Slip Detection and Classification for Grip Control using Multiple Sensory Modalities<br>on a Biomimetic Tactile Sensor</a><br>IROS Workshop on Multimodal Sensor-Based Robot Control for HRI and Soft Manipulation, 2015<br>
		<small class="authors">
		Z. Su, K. Hausman, Y. Chebotar, A. Molchanov, G. Loeb, G. Sukhatme, S. Schaal
		</small>
		<a href="bibtex/zhesu15-ws-iros.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
		<a href="pdf/zhesu15-ws-iros.pdf" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>

		<br><br>
		<a href="pdf/hausman-iros14-ws-ior.pdf">Towards Interactive Object Recognition</a><br>IROS 3rd Workshop on Robots in Clutter: Perception and Interaction in Clutter, 2014<br>
		<small class="authors">
		K. Hausman, C. Corcos, J. Mueller, F. Sha, G. Sukhatme
		</small>
		<a href="bibtex/hausman14iros-ws-b.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
		<a href="pdf/hausman-iros14-ws-ior.pdf" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>

		<br><br>
		<a href="pdf/hausman12interactive.pdf">Segmentation of Cluttered Scenes through Interactive Perception</a><br>ICRA Workshop on Semantic Perception and Mapping for Knowledge-enabled Service Robotics, 2012<br>
		<small class="authors">
		K. Hausman, C. Bersch, D. Pangercic, S. Osentoski, Z. Marton, M. Beetz
		</small>
		<a href="bibtex/hausman12icra-ws.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
		<a href="pdf/hausman12interactive.pdf" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>

		<br><br>
		<a href="pdf/bersch12interactive.pdf">Segmentation of Textured and Textureless Objects through Interactive Perception</a><br>RSS Workshop on Robots in Clutter: Manipulation, Perception and Navigation in Human Environments, 2012<br>
		<small class="authors">
		C. Bersch, D. Pangercic, S. Osentoski, K. Hausman, Z. Marton, R. Ueda, K. Okada, M. Beetz
		</small>
		<a href="bibtex/bersch12rss-ws.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
		<a href="pdf/bersch12interactive.pdf" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>
		<br>
<!--
<small>
<a href="bibtex/aaai-16.txt">bibtex</a> — <a href="pdf/Houthooft2016_AAAI.pdf">pdf</a>
</small>
-->
		</th>
	</tr>
	</table>

		<br><br><br><br>
		<h3>
		Active Perception
		</h3>
		<p class="text-justify">
In robotics, the research field of Active Perception pioneered the insight that perception is active and exploratory. In my research, I try to show that, state estimation (perception) can be significantly improved when considered jointly with control (action). I demonstrate my research results on various flying vehicles such as quadrotors. 		</p>

<!--	<table class="entry">
	<tr>
	<th>
		<img width="170" style="margin-bottom: 80px" src="img/thumbnails/rf.png" class="rein-paper"/>
	</th>
		<th class="entry">

		<a href="https://www.hindawi.com/journals/cmmm/2016/7087053/abs/">Random Survival Forests for Predicting the Bed Occupancy in the Intensive Care Unit</a><br>Computational and Mathematical Methods in Medicine, 2016<br>
<small class="authors">
J. Ruyssinck, J. van der Herten, R. Houthooft, F. Ongenae, I. Couckuyt, B. Gadeyne, K. Colpaert, J. Decruyenaere, F. De Turck, T. Dhaene</small>
<br>
<ul class="list-inline list-inline-x text-left">
<li>
<a href="bibtex/cm" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
</li>
<li>
<a href="http://downloads.hindawi.com/journals/cmmm/2016/7087053.pdf" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>
</li>
</ul>
<small>
<a href="bibtex/cm">bibtex</a> — <a href="http://downloads.hindawi.com/journals/cmmm/2016/7087053.pdf">pdf</a>
</small>
		</th>
	</tr>
	</table>	-->


	<table class="entry">
	<tr>
	<th>
		<img width="160" src="img/thumbnails/ijrr17preiss.png" class="rein-paper"/>
	</th>
		<th class="entry">

		<a href="">Simultaneous Self-Calibration and Navigation using Trajectory Optimization</a><br>International Journal of Robotics Research (IJRR), 2017 (under review)<br>
<small class="authors">
J. Preiss, K. Hausman, G. Sukhatme, S. Weiss
</small>
<br>
<ul class="list-inline list-inline-x text-left">
<!--<li>
<a href="bibtex/agha17isrr.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
</li>
<li>
<a href="http://people.lids.mit.edu/aliagha/Web/pubpdfs/2017.Ali.Heiden.ea.CRM.pdf" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>
</li> -->
</ul> 

<!--
<small>
<a href="bibtex/pr.txt">bibtex</a> — <a href="http://arxiv.org/pdf/1508.00451v4.pdf">pdf</a>
</small>
-->
		</th>
		</tr>
	</table>


	<table class="entry">
	<tr>
	<th>
		<img width="130" src="img/thumbnails/grid3d.png" class="rein-paper"/>
	</th>
		<th class="entry">

		<a href="">Confidence-rich Grid Mapping</a><br>International Symposium on Robotics Research (ISRR), 2017<br>
<small class="authors">
A. Agha-mohammadi, E. Heiden, K. Hausman, G. Sukhatme
</small>
<br>
<ul class="list-inline list-inline-x text-left">
<li>
<a href="bibtex/agha17isrr.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
</li>
<li>
<a href="http://people.lids.mit.edu/aliagha/Web/pubpdfs/2017.Ali.Heiden.ea.CRM.pdf" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>
</li> 
</ul> 

<!--
<small>
<a href="bibtex/pr.txt">bibtex</a> — <a href="http://arxiv.org/pdf/1508.00451v4.pdf">pdf</a>
</small>
-->
		</th>
		</tr>
	</table>


	<table class="entry">
	<tr>
	<th>
		<img width="150" src="img/thumbnails/calibration-navigation.png" class="rein-paper"/>
	</th>
		<th class="entry">

		<a href="https://storage.googleapis.com/rss2017-papers/70.pdf">Trajectory Optimization for Self-Calibration and Navigation
</a> &emsp; &emsp; &emsp;  
<br>Robotics: Science and Systems (RSS), 2017<br>
<small class="authors">
J. Preiss, K. Hausman, G. Sukhatme, S. Weiss
</small>
<br>
<ul class="list-inline list-inline-x text-left">
<li>
<a href="bibtex/preiss17rss.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
</li>
<li>
<a href="https://storage.googleapis.com/rss2017-papers/70.pdf" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>
</li>
</ul>
<!--
<small>
<a href="bibtex/pr.txt">bibtex</a> — <a href="http://arxiv.org/pdf/1508.00451v4.pdf">pdf</a>
</small>
-->
		</th>
		</tr>
	</table>

	<table class="entry">
	<tr>
	<th>
		<img width="170" src="img/thumbnails/iros-smap-planning.png" class="rein-paper"/>
	</th>
		<th class="entry">

		<a href="">Planning High-speed Safe Trajectories in Confidence-rich Map</a><br>International Conference on Intelligent Robots and Systems (IROS), 2017<br>
<small class="authors">
E. Heiden, K. Hausman, G. Sukhatme, A. Agha-mohammadi
</small>
<br>
<ul class="list-inline list-inline-x text-left">
<!--<li> <a href="">Coming soon!</a> </li> -->
<li>
<a href="bibtex/heiden17iros.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
</li>
<li>
<a href="http://people.lids.mit.edu/aliagha/Web/pubpdfs/2017.Eric.Ali.ea.IROS_SMAP_Planning.pdf" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>
</li> 
</ul> 

<!--
<small>
<a href="bibtex/pr.txt">bibtex</a> — <a href="http://arxiv.org/pdf/1508.00451v4.pdf">pdf</a>
</small>
-->
		</th>
		</tr>
	</table>

	<table class="entry">
	<tr>
	<th>
		<img width="170" src="img/thumbnails/self-calibration.png" class="rein-paper"/>
	</th>
		<th class="entry">

		<a href="https://arxiv.org/abs/1604.07905">Observability-Aware Trajectory Optimization for Self-Calibration with Application to UAVs</a><br>Robotics and Automation Letter (RA-L), 2017<br>
<small class="authors">
K. Hausman, J. Preiss, G. Sukhatme, S. Weiss
</small>
<br>
<ul class="list-inline list-inline-x text-left">
<li>
<a href="http://dblp.uni-trier.de/rec/bibtex/journals/corr/HausmanPSW16" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
</li>
<li>
<a href="https://arxiv.org/pdf/1604.07905.pdf" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>
</li>
<li>
<a href="https://www.youtube.com/watch?v=v8UkOtRJEsw&feature=youtu.be" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-video-camera fa-fw"></i> <span class="network-name">video</span></a>
</li>
</ul> 
<!--
<small>
<a href="bibtex/pr.txt">bibtex</a> — <a href="http://arxiv.org/pdf/1508.00451v4.pdf">pdf</a>
</small>
-->
		</th>
		</tr>
	</table>

	<table class="entry">
	<tr>
	<th>
		<img width="170" height="200" src="img/thumbnails/tracking.png" class="rein-paper"/>
	</th>
		<th class="entry">

		<a href="pdf/hausman16iros.pdf">Occlusion-Aware Multi-Robot 3D Tracking</a>
		<br>International Conference on Intelligent Robots and Systems (IROS), 2016<br>
		<small class="authors">
		K. Hausman, G. Kahn, S. Patil, J. Mueller, K. Goldberg, P. Abbeel, G. Sukhatme
		</small>
		<br>
<ul class="list-inline list-inline-x text-left">
<li>
<a href="bibtex/hausman16iros.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
</li>
<li>
<a href="pdf/hausman16iros.pdf" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>
</li>
<li>
<a href="https://youtu.be/poG1gEsenj4" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-video-camera fa-fw"></i> <span class="network-name">video</span></a>
</li>
<!--
<small>
<a href="bibtex/pr.txt">bibtex</a> — <a href="http://arxiv.org/pdf/1508.00451v4.pdf">pdf</a>
</small>
-->
		</th>
		</tr>
	</table>

	<table class="entry">
	<tr>
	<th>
		<img width="170" src="img/thumbnails/multiple.png" class="rein-paper"/>
	</th>
		<th class="entry">

		<a href="http://journals.sagepub.com/doi/abs/10.1177/0278364915602321?etoc=">Cooperative Multi-Robot Control for Target Tracking with Onboard Sensing</a>
		<br>International Journal of Robotics Research (IJRR), 2015<br>
		<small class="authors">
		K. Hausman, J. Mueller, A. Hariharan, N. Ayanian, G. Sukhatme
		</small>
		<br>
<ul class="list-inline list-inline-x text-left">
<li>
<a href="bibtex/hausman15ijrr.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
</li>
<li>
<a href="http://journals.sagepub.com/doi/abs/10.1177/0278364915602321?etoc=" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>
</li>
<!--
<small>
<a href="bibtex/pr.txt">bibtex</a> — <a href="http://arxiv.org/pdf/1508.00451v4.pdf">pdf</a>
</small>
-->
		</th>
		</tr>
	</table>

	<table class="entry">
	<tr>
	<th>
		<img width="170" src="img/thumbnails/jpl.png" class="rein-paper"/>
	</th>
		<th class="entry">

		<a href="pdf/hausman16icra.pdf">Self-Calibrating Multi-Sensor Fusion with Probabilistic Measurement Validation for Seamless Sensor Switching on a UAV</a>
		<br>International Conference on Robotics and Automation (ICRA), 2016<br>
		<small class="authors">
		K. Hausman, S. Weiss, R. Brockers, L. Matthies, G. Sukhatme
		</small>
		<br>
<ul class="list-inline list-inline-x text-left">
<li>
<a href="bibtex/hausman16icra.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
</li>
<li>
<a href="pdf/hausman16icra.pdf" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>
</li>
<li>
<a href="https://www.youtube.com/watch?v=po3PqC2FGxY" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-video-camera fa-fw"></i> <span class="network-name">video</span></a>
</li>
<!--
<small>
<a href="bibtex/pr.txt">bibtex</a> — <a href="http://arxiv.org/pdf/1508.00451v4.pdf">pdf</a>
</small>
-->
		</th>
		</tr>
	</table>

	<table class="entry">
	<tr>
	<th>
		<img width="170" src="img/thumbnails/multiple2.png" class="rein-paper"/>
	</th>
		<th class="entry">

		<a href="pdf/hausman14iser.pdf">Cooperative Control for Target Tracking with Onboard Sensing </a>&emsp; &emsp; &emsp;
		<br>International Symposium on Experimental Robotics (ISER), 2014<br>
		<small class="authors">
		K. Hausman, J. Mueller, A. Hariharan, N.Ayanian, G. Sukhatme
		</small>
		<br>
<ul class="list-inline list-inline-x text-left">
<li>
<a href="bibtex/hausman14iser.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
</li>
<li>
<a href="pdf/hausman14iser.pdf" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>
</li>
<li>
<a href="https://www.youtube.com/watch?v=2AhDYF8QROE" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-video-camera fa-fw"></i> <span class="network-name">video</span></a>
</li>
<small>
<!--<a href="bibtex/infogan-nips-16.txt">bibtex</a> — <a href="https://arxiv.org/pdf/1606.03657v1.pdf">pdf</a> — <a href="https://github.com/openai/InfoGAN">github</a> — <a href="https://openai.com/blog/generative-models/"> blog post </a>
</small>
-->
	</th>
	</tr>
	</table>

	<table class="entry">
	<tr>
	<th>
	</th>
	<th class="entry workshops">
		<h4>Workshop Publications</h4>
		<a href="pdf/agha17-ws-iros.pdf">Confidence-aware Occupancy Grids</a><br> IROS Workshop on Vision-based Agile Autonomous Navigation of UAVs, 2017<br>
		<small class="authors">
		A. Agha-mohammadi, E. Heiden, K. Hausman, G. Sukhatme
		</small>
		<a href="bibtex/agha17-ws-iros.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
		<a href="pdf/agha17-ws-iros.pdf" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>

		<br><br>
		<a href="pdf/heiden17-ws-iros.pdf">High-speed Safe Trajectory Planning in Confidence-rich Maps</a><br> IROS Workshop on Vision-based Agile Autonomous Navigation of UAVs, 2017<br>
		<small class="authors">
		E. Heiden, K. Hausman, G. Sukhatme, A. Agha-mohammadi
		</small>
		<a href="bibtex/heiden17-ws-iros.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
		<a href="pdf/heiden17-ws-iros.pdf" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>

		<br><br>
		<a href="pdf/hausman16-ws-rss.pdf">Observability-Aware Trajectory Optimization for Self-Calibration with Application to UAVs</a><br> RSS Workshop on Robot-Environment Interaction for Perception and Manipulation, 2016<br>
		<small class="authors">
		K. Hausman, J. Preiss, G. Sukhatme, S. Weiss
		</small>
		<a href="bibtex/hausman16-ws-rss.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
		<a href="pdf/hausman16-ws-rss.pdf" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>

		<br><br>
		<a href="pdf/hausman15-ws-iros.pdf">Optimization-based Cooperative Multi-Robot Target Tracking<br>with Reasoning about Occlusions</a><br>IROS Workshop on On-line Decision-Making in Multi-Robot Coordination, 2015<br>
		<small class="authors">
		K. Hausman, G. Kahn, S. Patil, J. Mueller, K. Goldberg, P. Abbeel, G. Sukhatme
		</small>
		<a href="bibtex/hausman15-ws-iros.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
		<a href="pdf/hausman15-ws-iros.pdf" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>

		<br><br>
		<a href="pdf/iros14-ws-topology.pdf">Cooperative Multi-Robot Control for Target Tracking<br>with Efficient Switching of Onboard Sensing Topologies</a><br>IROS Workshop on Taxonomies of Interconnected Systems:<br>Topology in Distributed Robotics, 2014<br>
		<small class="authors">
		K. Hausman, J. Mueller, A. Hariharan, N. Ayanian, G. Sukhatme
		</small>
		<a href="bibtex/hausman14iros-ws-a.bib" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-text-o fa-fw"></i> <span class="network-name">bibtex</span></a>
		<a href="pdf/iros14-ws-topology.pdf" target="_blank" class="btn-x btn-default-x btn-lg-x"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="network-name">pdf</span></a>

		<br>
<!--
<small>
<a href="bibtex/aiim.txt">bibtex</a> — <a href="pdf/Houthooft2015_AIIM.pdf">pdf</a>
</small>
-->
</th>
</tr>
	</table>

            </div>
</div>
    </section>

    
    
    <!-- Footer -->
    <!--<footer>
        <div class="container text-center">
            <p>
<a href="#page-top" onclick="setActiveStyleSheet('default'); return false;" class="page-scroll">&mdash;</a>
<a href="#page-top" onclick="setActiveStyleSheet('white'); return false;" class="page-scroll">&mdash;</a>
	</p>
        </div>
    </footer>-->

    <!-- jQuery -->
    <script src="js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="js/jquery.easing.min.js"></script>

    <!-- Google Maps API Key - Use your own API key to enable the map feature. More information on the Google Maps API can be found at https://developers.google.com/maps/ 
    <script type="text/javascript" src="https://maps.googleapis.com/maps/api/js?key=AIzaSyCRngKslUGJTlibkQ3FkfTxj3Xss1UlZDA&sensor=false"></script>-->

    <!-- Custom Theme JavaScript -->
    <script src="js/grayscale.js"></script>


</body>

</html>
